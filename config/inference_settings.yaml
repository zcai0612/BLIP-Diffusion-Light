model:
  # pretrained stable diffusion model path, default: 'runwayml/stable-diffusion-v1-5'
  sd_pretrained_path: "D:/apps/tools/programming/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/c9ab35ff5f2c362e9e22fbafe278077e196057f0" 
  # blip-diffusion pretrained path
  pretrained_path: "D:/my_files/projects/2D_Generation/my_blip_diffusion/weights/blip-diffusion"

  controlnet_path: "D:/apps/tools/programming/.cache/huggingface/controlnet/sd-controlnet-openpose"
  controlnet_path: ''

  # mixed_precision: True
  mixed_precision: False

run:
  cond_subject: 'dog'
  tgt_subject: 'dog'
  txt_prompt: "in batman suit"

  cond_image_path: "images/subjects/dog/dog.png"
  # for controlnet
  # cldm_cond_image_path: "images/controls/pose1.jpeg"
  cldm_cond_image_path: ""


  num_output: 3
  iter_seed: 88888
  guidance_scale: 7.5
  num_inference_steps: 50
  negative_prompt: "over-exposure, under-exposure, saturated, duplicate, out of frame, lowres, cropped, worst quality, low quality, jpeg artifacts, morbid, mutilated, out of frame, ugly, bad anatomy, bad proportions, deformed, blurry, duplicate"
  
  output_dir: 'outputs/'
