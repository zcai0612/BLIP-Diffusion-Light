model:
  # pretrained stable diffusion model path, default: 'runwayml/stable-diffusion-v1-5'
  sd_pretrained_path: "D:/apps/tools/programming/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/c9ab35ff5f2c362e9e22fbafe278077e196057f0" 
  # blip-diffusion pretrained path
  pretrained_path: "D:/my_files/projects/2D_Generation/my_blip_diffusion/weights/blip-diffusion"

  controlnet_path: "D:/apps/tools/programming/.cache/huggingface/controlnet/sd-controlnet-openpose"

  mixed_precision: True

run:
  cond_subject: 'man'
  tgt_subject: 'man'
  txt_prompt: "wearing Superman's suit."

  cond_image_path: "images/subjects/man/man1.jpg"
  # for controlnet
  cldm_cond_image_path: "images/controls/pose1.jpeg"

  num_output: 1
  iter_seed: 8888
  guidance_scale: 7.5
  num_inference_steps: 50
  negative_prompt: "over-exposure, under-exposure, saturated, duplicate, out of frame, lowres, cropped, worst quality, low quality, jpeg artifacts, morbid, mutilated, out of frame, ugly, bad anatomy, bad proportions, deformed, blurry, duplicate"
  
  output_dir: 'outputs/'
